# IR_Web_Search_Engine

## Part 1
Build a Web Crawler for edu pages.
Your application should read a file of seed .edu URLs and crawl the .edu pages.
The application should also input the number of pages to crawl and the number of levels (hops (i.e. hyperlinks) away from the seed URLs).
All crawled pages (html files) should be stored in a folder.
You should collect at least 5 GB of data.

## Part 2
Build index and Web-based search interface.
Write a program that uses the Lucene libraries to index all the html files in the folder you created in Part A. Handle different fields like title, body, creation date (if available).
